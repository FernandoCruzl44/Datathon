{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_vuelos = pd.read_csv(\"Flights.csv\")\n",
    "datos_ventas = pd.read_csv(\"Sales.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productos_a_eliminar = [\n",
    "    \"Vivabus\",\n",
    "    \"Transportaciones CUN\",\n",
    "    \"Specials\",\n",
    "    \"COMBOS CREW\",\n",
    "    \"Hertz.\",\n",
    "    \"OFERTAS\",\n",
    "    \"Transportaciones MTY\",\n",
    "    \"Transportaciones TLC\",\n",
    "    \"VIVA PLAY\",\n",
    "    \"VIVA Taxis\",\n",
    "    \"Antros\",\n",
    "    \"VivaTransfer\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos_product_type = datos_ventas[\"ProductType\"].unique()\n",
    "\n",
    "# Imprimir los distintos tipos de ProductType\n",
    "print(\"Distintos tipos de ProductType:\")\n",
    "for tipo in tipos_product_type:\n",
    "    print(tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesClean = datos_ventas\n",
    "for i in productos_a_eliminar:\n",
    "    salesClean = salesClean [salesClean[\"ProductType\"] != i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesClean.to_csv(\"files/salesClean.csv\", index=False)\n",
    "\n",
    "# Verificamos la existencia del archivo\n",
    "if os.path.exists(\"salesClean.csv\"):\n",
    "    print(\"Archivo salesClean.csv creado con éxito!\")\n",
    "else:\n",
    "    print(\"Error al crear el archivo salesClean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad de filas (resultados) en el dataframe\n",
    "numero_resultados = salesClean.shape[0]\n",
    "\n",
    "# Imprimir la cantidad de resultados\n",
    "print(\"Cantidad de resultados en salesClean.csv:\", numero_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inner Join\n",
    "datos_unidos = datos_vuelos.merge(salesClean, on=\"Flight_ID\", how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_unidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_JoinFull = \"files/JoinDataFull.csv\"\n",
    "datos_unidos.to_csv(link_JoinFull, index=False)\n",
    "\n",
    "# Verificamos la existencia del archivo\n",
    "if os.path.exists(link_JoinFull):\n",
    "    print(\"Archivo salesClean.csv creado con éxito!\")\n",
    "else:\n",
    "    print(\"Error al crear el archivo {link}\",link_JoinFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#En files crea un archivo cleanFlights que contenga los datos sin datos nulos\n",
    "#vuelos_limpios = datos_vuelos.dropna()\n",
    "\n",
    "# Extract the year from the date column\n",
    "datos_vuelos['Year'] = pd.to_datetime(datos_vuelos['STD']).dt.year\n",
    "\n",
    "# Manda lo salvado a un csv nuevo\n",
    "#vuelos_limpios.to_csv('files/cleanFlights.csv', index=False)\n",
    "\n",
    "# Filtrar los datos para 2023\n",
    "datos_2023 = datos_vuelos[datos_vuelos['Year'] == 2023]\n",
    "\n",
    "limpios2023 = datos_2023.dropna()\n",
    "\n",
    "limpios2023.to_csv('files/limpios2023.csv', index=False)\n",
    "\n",
    "# Filtrar los datos para 2024\n",
    "datos_2024 = datos_vuelos[datos_vuelos['Year'] == 2024]\n",
    "# Filtrar los datos para 2024\n",
    "datos_2025 = datos_vuelos[datos_vuelos['Year'] == 2025]\n",
    "\n",
    "# Guardar los datos de 2023 en un archivo CSV\n",
    "datos_2023.to_csv('files/datos_2023.csv', index=False)\n",
    "\n",
    "# Guardar los datos de 2024 en un archivo CSV\n",
    "datos_2024.to_csv('files/datos_2024.csv', index=False)\n",
    "\n",
    "#Compara la cantidad de resultados cleanFlights con filghts 2023\n",
    "#print(\"Cantidad de resultados en cleanFlights.csv:\", vuelos_limpios.shape[0])\n",
    "print(\"Cantidad de resultados en datos_2023.csv:\", datos_2023.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
